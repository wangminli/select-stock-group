"""
é‚¢ä¸è¡Œâ„¢ï¸é€‰è‚¡æ¡†æ¶
Pythonè‚¡ç¥¨é‡åŒ–æŠ•èµ„è¯¾ç¨‹

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx8662

æœªç»æˆæƒï¼Œä¸å¾—å¤åˆ¶ã€ä¿®æ”¹ã€æˆ–ä½¿ç”¨æœ¬ä»£ç çš„å…¨éƒ¨æˆ–éƒ¨åˆ†å†…å®¹ã€‚ä»…é™ä¸ªäººå­¦ä¹ ç”¨é€”ï¼Œç¦æ­¢å•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""
import json
import os
import random
import time

import numpy as np
import pandas as pd
import requests

from core.figure import draw_equity_curve_plotly

pd.set_option('expand_frame_repr', False)
pd.set_option('future.no_silent_downcasting', True)
# printè¾“å‡ºä¸­æ–‡è¡¨å¤´å¯¹é½
pd.set_option('display.unicode.ambiguous_as_wide', True)
pd.set_option('display.unicode.east_asian_width', True)


def cal_fuquan_price(df, fuquan_type='åå¤æƒ', method=None):
    """
    ç”¨äºè®¡ç®—å¤æƒä»·æ ¼

    å‚æ•°:
    df (DataFrame): å¿…é¡»åŒ…å«çš„å­—æ®µï¼šæ”¶ç›˜ä»·ï¼Œå‰æ”¶ç›˜ä»·ï¼Œå¼€ç›˜ä»·ï¼Œæœ€é«˜ä»·ï¼Œæœ€ä½ä»·
    fuquan_type (str, optional): å¤æƒç±»å‹ï¼Œå¯é€‰å€¼ä¸º 'å‰å¤æƒ' æˆ– 'åå¤æƒ'ï¼Œé»˜è®¤ä¸º 'åå¤æƒ'
    method (str, optional): é¢å¤–è®¡ç®—å¤æƒä»·æ ¼çš„æ–¹æ³•ï¼Œå¦‚ 'å¼€ç›˜'ï¼Œé»˜è®¤ä¸º None

    è¿”å›:
    DataFrame: æœ€ç»ˆè¾“å‡ºçš„dfä¸­ï¼Œæ–°å¢å­—æ®µï¼šæ”¶ç›˜ä»·_å¤æƒï¼Œå¼€ç›˜ä»·_å¤æƒï¼Œæœ€é«˜ä»·_å¤æƒï¼Œæœ€ä½ä»·_å¤æƒ
    """

    # è®¡ç®—å¤æƒå› å­
    fq_factor = (df['æ”¶ç›˜ä»·'] / df['å‰æ”¶ç›˜ä»·']).cumprod()

    # è®¡ç®—å‰å¤æƒæˆ–åå¤æƒæ”¶ç›˜ä»·
    if fuquan_type == 'åå¤æƒ':  # å¦‚æœä½¿ç”¨åå¤æƒæ–¹æ³•
        fq_close = fq_factor * (df.iloc[0]['æ”¶ç›˜ä»·'] / fq_factor.iloc[0])
    elif fuquan_type == 'å‰å¤æƒ':  # å¦‚æœä½¿ç”¨å‰å¤æƒæ–¹æ³•
        fq_close = fq_factor * (df.iloc[-1]['æ”¶ç›˜ä»·'] / fq_factor.iloc[-1])
    else:  # å¦‚æœç»™çš„å¤æƒæ–¹æ³•éä¸Šè¿°ä¸¤ç§æ ‡å‡†æ–¹æ³•ä¼šæŠ¥é”™
        raise ValueError(f'è®¡ç®—å¤æƒä»·æ—¶ï¼Œå‡ºç°æœªçŸ¥çš„å¤æƒç±»å‹ï¼š{fuquan_type}')

    # è®¡ç®—å…¶ä»–ä»·æ ¼çš„å¤æƒå€¼
    fq_open = df['å¼€ç›˜ä»·'] / df['æ”¶ç›˜ä»·'] * fq_close
    fq_high = df['æœ€é«˜ä»·'] / df['æ”¶ç›˜ä»·'] * fq_close
    fq_low = df['æœ€ä½ä»·'] / df['æ”¶ç›˜ä»·'] * fq_close

    # ä¸€æ¬¡æ€§èµ‹å€¼ï¼Œæé«˜è®¡ç®—æ•ˆç‡
    df = df.assign(
        å¤æƒå› å­=fq_factor,
        æ”¶ç›˜ä»·_å¤æƒ=fq_close,
        å¼€ç›˜ä»·_å¤æƒ=fq_open,
        æœ€é«˜ä»·_å¤æƒ=fq_high,
        æœ€ä½ä»·_å¤æƒ=fq_low,
    )

    # å¦‚æœæŒ‡å®šäº†é¢å¤–çš„æ–¹æ³•ï¼Œè®¡ç®—è¯¥æ–¹æ³•çš„å¤æƒä»·æ ¼
    if method and method != 'å¼€ç›˜':
        df[f'{method}_å¤æƒ'] = df[method] / df['æ”¶ç›˜ä»·'] * fq_close

    # åˆ é™¤ä¸­é—´å˜é‡å¤æƒå› å­
    # df.drop(columns=['å¤æƒå› å­'], inplace=True)

    return df


def get_file_in_folder(path, file_type, contains=None, filters=(), drop_type=False):
    """
    è·å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶

    å‚æ•°:
    path (str): æ–‡ä»¶å¤¹è·¯å¾„
    file_type (str): æ–‡ä»¶ç±»å‹ï¼Œä¾‹å¦‚ '.csv' æˆ– '.txt'
    contains (str, optional): æ–‡ä»¶åä¸­éœ€è¦åŒ…å«çš„å­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸º None
    filters (list, optional): æ–‡ä»¶åä¸­éœ€è¦è¿‡æ»¤æ‰çš„å†…å®¹ï¼Œåˆ—è¡¨å½¢å¼ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨
    drop_type (bool, optional): æ˜¯å¦è¦å»é™¤æ–‡ä»¶æ‰©å±•åï¼Œé»˜è®¤ä¸º False

    è¿”å›:
    list: ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ååˆ—è¡¨
    """
    # è·å–æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å
    file_list = os.listdir(path)

    # è¿‡æ»¤å‡ºæŒ‡å®šç±»å‹çš„æ–‡ä»¶
    file_list = [file for file in file_list if file.endswith(file_type)]

    # å¦‚æœæŒ‡å®šäº†åŒ…å«çš„å­—ç¬¦ä¸²ï¼Œè¿›ä¸€æ­¥è¿‡æ»¤
    if contains:
        file_list = [file for file in file_list if contains in file]

    # è¿‡æ»¤æ‰æŒ‡å®šçš„å†…å®¹
    for con in filters:
        file_list = [file for file in file_list if con not in file]

    # å¦‚æœéœ€è¦å»é™¤æ–‡ä»¶æ‰©å±•å
    if drop_type:
        file_list = [file[:file.rfind('.')] for file in file_list]

    return file_list


def import_index_data(path, date_range=(None, None), max_param=0):
    """
    å¯¼å…¥æŒ‡æ•°æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†

    å‚æ•°:
    path (str): æŒ‡æ•°æ•°æ®æ–‡ä»¶çš„è·¯å¾„
    date_range (list, optional): å›æµ‹çš„æ—¶é—´èŒƒå›´ï¼Œæ ¼å¼ä¸º [å¼€å§‹æ—¥æœŸ, ç»“æŸæ—¥æœŸ]ï¼Œé»˜è®¤ä¸º [None, None]
    max_param (int, optional): å› å­çš„æœ€å¤§å‘¨æœŸæ•°ï¼Œç”¨äºæ§åˆ¶å¼€å§‹æ—¥æœŸï¼Œç¡®ä¿rollingç±»å› å­ï¼Œå‰ç½®æ•°æ®ä¸æ˜¯NaNï¼Œé»˜è®¤ä¸º 0

    è¿”å›:
    DataFrame: å¤„ç†åçš„æŒ‡æ•°æ•°æ®ï¼ŒåŒ…å«äº¤æ˜“æ—¥æœŸå’ŒæŒ‡æ•°æ¶¨è·Œå¹…
    """
    # å¯¼å…¥æŒ‡æ•°æ•°æ®
    df_index = pd.read_csv(path, parse_dates=['candle_end_time'], encoding='gbk')

    # è®¡ç®—æ¶¨è·Œå¹…
    df_index['æŒ‡æ•°æ¶¨è·Œå¹…'] = df_index['close'].pct_change()
    # ç¬¬ä¸€å¤©çš„æŒ‡æ•°æ¶¨è·Œå¹…æ˜¯å¼€ç›˜ä¹°å…¥çš„æ¶¨è·Œå¹…
    df_index['æŒ‡æ•°æ¶¨è·Œå¹…'] = df_index['æŒ‡æ•°æ¶¨è·Œå¹…'].fillna(value=df_index['close'] / df_index['open'] - 1)

    # ä¿ç•™å¿…è¦çš„åˆ—
    df_index = df_index[['candle_end_time', 'æŒ‡æ•°æ¶¨è·Œå¹…']]

    # å»é™¤æ¶¨è·Œå¹…ä¸ºç©ºçš„è¡Œ
    df_index.dropna(subset=['æŒ‡æ•°æ¶¨è·Œå¹…'], inplace=True)

    # é‡å‘½ååˆ—
    df_index.rename(columns={'candle_end_time': 'äº¤æ˜“æ—¥æœŸ'}, inplace=True)

    # æ ¹æ®æ—¥æœŸèŒƒå›´è¿‡æ»¤æ•°æ®
    if date_range[0]:
        if max_param == 0:
            df_index = df_index[df_index['äº¤æ˜“æ—¥æœŸ'] >= pd.to_datetime(date_range[0])]
            # print(f'ğŸ’¡ å›æµ‹å¼€å§‹æ—¶é—´ï¼š{df_index["äº¤æ˜“æ—¥æœŸ"].iloc[0].strftime("%Y-%m-%d")}')
        # å½“æä¾›äº†å‘¨æœŸæ•°ä¹‹å
        else:
            # è®¡ç®—æ–°çš„å¼€å§‹æ—¥æœŸ
            start_index = df_index[df_index['äº¤æ˜“æ—¥æœŸ'] >= pd.to_datetime(date_range[0])].index[0]
            start_date = df_index['äº¤æ˜“æ—¥æœŸ'][start_index].strftime("%Y-%m-%d")

            # ç§»åŠ¨å‘¨æœŸï¼Œè·å–å¯ä»¥è®©å› å­æ•°å€¼ä¸ä¸ºNançš„å¼€å§‹æ—¥æœŸ
            shifted_date = df_index['äº¤æ˜“æ—¥æœŸ'].shift(max_param)
            shifted_date.bfill(inplace=True)  # å‰ç½®æ•°æ®ä¸æ˜¯NaN

            # è¿‡æ»¤å‰ç½®æ•°æ®
            df_index = df_index[df_index['äº¤æ˜“æ—¥æœŸ'] >= shifted_date[start_index]]
            new_start_date = df_index['äº¤æ˜“æ—¥æœŸ'].iloc[0].strftime("%Y-%m-%d")
            print(f'ğŸ’¡ å›æµ‹å¼€å§‹æ—¶é—´ï¼š{start_date}ï¼Œç§»åŠ¨{max_param}ä¸ªå‘¨æœŸï¼Œæœ€æ–°äº¤æ˜“æ—¥ï¼š{new_start_date}')
    if date_range[1]:
        df_index = df_index[df_index['äº¤æ˜“æ—¥æœŸ'] <= pd.to_datetime(date_range[1])]
        # print(f'å›æµ‹ç»“æŸæ—¶é—´ï¼š{df_index["äº¤æ˜“æ—¥æœŸ"].iloc[-1].strftime("%Y-%m-%d")}')

    # æŒ‰æ—¶é—´æ’åºå¹¶é‡ç½®ç´¢å¼•
    df_index.sort_values(by=['äº¤æ˜“æ—¥æœŸ'], inplace=True)
    df_index.reset_index(inplace=True, drop=True)

    return df_index


def merge_with_index_data(df, index_data, fill_0_list=()):
    """
    åŸå§‹è‚¡ç¥¨æ•°æ®åœ¨ä¸äº¤æ˜“çš„æ—¶å€™æ²¡æœ‰æ•°æ®ã€‚
    å°†åŸå§‹è‚¡ç¥¨æ•°æ®å’ŒæŒ‡æ•°æ•°æ®åˆå¹¶ï¼Œå¯ä»¥è¡¥å…¨åŸå§‹è‚¡ç¥¨æ•°æ®æ²¡æœ‰äº¤æ˜“çš„æ—¥æœŸã€‚

    å‚æ•°:
    df (DataFrame): è‚¡ç¥¨æ•°æ®
    index_data (DataFrame): æŒ‡æ•°æ•°æ®
    extra_fill_0_list (list, optional): åˆå¹¶æ—¶éœ€è¦å¡«å……ä¸º0çš„å­—æ®µï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨

    è¿”å›:
    DataFrame: åˆå¹¶åçš„è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…å«è¡¥å…¨çš„æ—¥æœŸ
    """
    # å°†è‚¡ç¥¨æ•°æ®å’ŒæŒ‡æ•°æ•°æ®åˆå¹¶ï¼Œç»“æœå·²ç»æ’åº
    df = pd.merge(left=df, right=index_data, on='äº¤æ˜“æ—¥æœŸ', how='right', sort=True, indicator=True)

    # å¯¹å¼€ã€é«˜ã€æ”¶ã€ä½ã€å‰æ”¶ç›˜ä»·ä»·æ ¼è¿›è¡Œè¡¥å…¨å¤„ç†
    # ç”¨å‰ä¸€å¤©çš„æ”¶ç›˜ä»·ï¼Œè¡¥å…¨æ”¶ç›˜ä»·çš„ç©ºå€¼
    close = df['æ”¶ç›˜ä»·'].ffill()
    # ç”¨æ”¶ç›˜ä»·è¡¥å…¨å¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·çš„ç©ºå€¼
    df = df.assign(
        æ”¶ç›˜ä»·=close,
        å¼€ç›˜ä»·=df['å¼€ç›˜ä»·'].fillna(value=close),
        æœ€é«˜ä»·=df['æœ€é«˜ä»·'].fillna(value=close),
        æœ€ä½ä»·=df['æœ€ä½ä»·'].fillna(value=close),
        å‡ä»·=df['å‡ä»·'].fillna(value=close),
        # è¡¥å…¨å‰æ”¶ç›˜ä»·
        å‰æ”¶ç›˜ä»·=df['å‰æ”¶ç›˜ä»·'].fillna(value=close.shift()),
    )

    # å¦‚æœå‰é¢ç®—è¿‡å¤æƒï¼Œå¤æƒä»·ä¹Ÿåšfillna
    if 'æ”¶ç›˜ä»·_å¤æƒ' in df.columns:
        fq_cols = dict()
        fq_cols['æ”¶ç›˜ä»·_å¤æƒ'] = df['æ”¶ç›˜ä»·_å¤æƒ'].ffill()
        for col in ['å¼€ç›˜ä»·_å¤æƒ', 'æœ€é«˜ä»·_å¤æƒ', 'æœ€ä½ä»·_å¤æƒ']:
            if col in df.columns:
                fq_cols[col] = df[col].fillna(value=fq_cols['æ”¶ç›˜ä»·_å¤æƒ'])
        df = df.assign(**fq_cols)

    # å°†åœç›˜æ—¶é—´çš„æŸäº›åˆ—ï¼Œæ•°æ®å¡«è¡¥ä¸º0
    fill_0_list = list(set(['æˆäº¤é‡', 'æˆäº¤é¢', 'æ¶¨è·Œå¹…'] + fill_0_list))
    df.loc[:, fill_0_list] = df[fill_0_list].fillna(value=0)

    # ç”¨å‰ä¸€å¤©çš„æ•°æ®ï¼Œè¡¥å…¨å…¶ä½™ç©ºå€¼
    df.ffill(inplace=True)

    # å»é™¤ä¸Šå¸‚ä¹‹å‰çš„æ•°æ®
    df = df[df['è‚¡ç¥¨ä»£ç '].notnull()]

    # åˆ¤æ–­è®¡ç®—å½“å¤©æ˜¯å¦äº¤æ˜“
    df['æ˜¯å¦äº¤æ˜“'] = np.int8(1)
    df.loc[df['_merge'] == 'right_only', 'æ˜¯å¦äº¤æ˜“'] = np.int8(0)
    del df['_merge']
    df.reset_index(drop=True, inplace=True)

    return df


def transfer_to_period_data(df, period, extra_agg_dict=None):
    """
    å°†æ—¥çº¿æ•°æ®è½¬æ¢ä¸ºç›¸åº”çš„å‘¨æœŸæ•°æ®

    å‚æ•°:
    df (DataFrame): åŸå§‹æ•°æ®
    period (str): éœ€è¦è½¬æ¢çš„æ•°æ®å‘¨æœŸï¼Œä¾‹å¦‚ 'W' è¡¨ç¤ºå‘¨é¢‘ï¼Œ'M' è¡¨ç¤ºæœˆé¢‘
    extra_agg_dict (dict, optional): é¢å¤–çš„èšåˆå­—å…¸ï¼Œé»˜è®¤ä¸ºç©ºå­—å…¸

    è¿”å›:
    DataFrame: è½¬æ¢åçš„å‘¨æœŸæ•°æ®
    """
    # åˆ›é€ ä¸€åˆ—ç”¨äºå‘¨æœŸæœ«çš„æ—¶é—´è®¡ç®—
    if extra_agg_dict is None:
        extra_agg_dict = {}
    df['å‘¨æœŸæœ€åäº¤æ˜“æ—¥'] = df['äº¤æ˜“æ—¥æœŸ']

    # agg_dict æ˜¯å‘¨æœŸå†…æ•°æ®æ•´åˆæ‰€å¿…é¡»çš„å­—å…¸ã€‚æ•°æ®æ•´åˆæ–¹æ³•åŒ…æ‹¬:
    # first(ä¿ç•™å‘¨æœŸå†…ç¬¬ä¸€æ¡æ•°æ®)ã€max(ä¿ç•™å‘¨æœŸå†…æœ€å¤§çš„æ•°æ®)ã€min(ä¿ç•™å‘¨æœŸå†…æœ€å°çš„æ•°æ®)ã€sum(å‘¨æœŸå†…æ‰€æœ‰æ•°æ®æ±‚å’Œ)ã€last(ä¿ç•™æœ€æ–°æ•°æ®)
    agg_dict = {
        # å¿…é¡»åˆ—
        'å‘¨æœŸæœ€åäº¤æ˜“æ—¥': 'last',
        'è‚¡ç¥¨ä»£ç ': 'last',
        'è‚¡ç¥¨åç§°': 'last',
        'æ˜¯å¦äº¤æ˜“': ['last', 'sum', 'count'],  # ç»Ÿè®¡å±€å’Œè®¡ç®—æ˜¯å¦äº¤æ˜“ï¼Œäº¤æ˜“å¤©æ•°ï¼Œå¸‚åœºäº¤æ˜“å¤©æ•°
        'å¼€ç›˜ä»·': 'first',
        'æœ€é«˜ä»·': 'max',
        'æœ€ä½ä»·': 'min',
        'æ”¶ç›˜ä»·': 'last',
        'æˆäº¤é¢': 'sum',
        'æµé€šå¸‚å€¼': 'last',
        'æ€»å¸‚å€¼': 'last',
        'ä¸Šå¸‚è‡³ä»Šäº¤æ˜“å¤©æ•°': 'last',
        'ä¸‹æ—¥_æ˜¯å¦äº¤æ˜“': 'last',
        'ä¸‹æ—¥_å¼€ç›˜æ¶¨åœ': 'last',
        'ä¸‹æ—¥_æ˜¯å¦ST': 'last',
        # 'ä¸‹æ—¥_æ˜¯å¦S': 'last',
        'ä¸‹æ—¥_æ˜¯å¦é€€å¸‚': 'last',
        # 'ä¸‹æ—¥_å¼€ç›˜ä¹°å…¥æ¶¨è·Œå¹…': 'last',
        'å¤æƒå› å­': 'last'
    }
    # åˆå¹¶é¢å¤–çš„èšåˆå­—å…¸
    agg_dict = {**agg_dict, **extra_agg_dict}

    # æ ¹æ®å‘¨æœŸoffsetæƒ…å†µï¼Œè¿›è¡Œgroupbyåï¼Œå¾—åˆ°å¯¹åº”çš„nD/å‘¨çº¿/æœˆçº¿æ•°æ®
    group_tag = f'{period}èµ·å§‹æ—¥'
    period_df = df.groupby(group_tag).agg(agg_dict)
    period_df.columns = [
        'æ˜¯å¦äº¤æ˜“' if col == ('æ˜¯å¦äº¤æ˜“', 'last') else
        'äº¤æ˜“å¤©æ•°' if col == ('æ˜¯å¦äº¤æ˜“', 'sum') else
        'å¸‚åœºäº¤æ˜“å¤©æ•°' if col == ('æ˜¯å¦äº¤æ˜“', 'count') else
        col[0] if isinstance(col, tuple) else col
        for col in period_df.columns
    ]  # é‡å‘½ååˆ—åï¼Œèšåˆä¹‹åçš„æ•°æ®åˆ—åæ˜¯è¿™æ ·çš„ï¼š... (è‚¡ç¥¨åç§°, last)  (æ˜¯å¦äº¤æ˜“, last)  (æ˜¯å¦äº¤æ˜“, sum)  (æ˜¯å¦äº¤æ˜“, count)  (å¼€ç›˜ä»·, first)  (æœ€é«˜ä»·, max) ...

    # è®¡ç®—å…¶ä»–å› å­
    # è®¡ç®—å‘¨æœŸèµ„é‡‘æ›²çº¿
    # period_df['æ¯å¤©æ¶¨è·Œå¹…'] = df.groupby(group_tag)['æ¶¨è·Œå¹…'].apply(lambda x: list(x))

    # å›½åº†èŠ‚ã€æ˜¥èŠ‚ç­‰å‡æœŸå¯èƒ½å¯¼è‡´Aè‚¡æ•´å‘¨ä¸äº¤æ˜“ï¼Œä»è€Œå‡ºç°ç©ºçš„å‘¨æœŸï¼Œéœ€è¦åˆ é™¤è¿™äº›ç©ºçš„å‘¨æœŸ
    period_df.dropna(subset=['è‚¡ç¥¨ä»£ç '], inplace=True)

    # è®¡ç®—æ¶¨è·Œå¹…
    period_pct_change = period_df['å¤æƒå› å­'].pct_change(fill_method=None)  # ç”¨å¤æƒæ”¶ç›˜ä»·è®¡ç®—
    first_ret = (np.array(period_pct_change.iloc[0]) + 1).prod() - 1  # ç¬¬ä¸€ä¸ªæŒä»“å‘¨æœŸçš„å¤åˆ©æ¶¨è·Œå¹…
    period_pct_change = period_pct_change.fillna(value=first_ret)  # pct_change()ç®—çš„ç¬¬ä¸€å¤©æ˜¯nanï¼Œä½†æ˜¯å®é™…æ˜¯å­˜åœ¨æ¶¨è·Œå¹…çš„ï¼Œè¿™é‡Œåšä¸ªä¿®æ­£
    period_df.rename(columns={'å‘¨æœŸæœ€åäº¤æ˜“æ—¥': 'äº¤æ˜“æ—¥æœŸ'}, inplace=True)

    period_df.assign(
        æ¶¨è·Œå¹…=period_pct_change,
        ä¸‹å‘¨æœŸæ¶¨è·Œå¹…=period_pct_change.shift(-1)
    )

    # é‡ç½®ç´¢å¼•
    period_df.reset_index(drop=True, inplace=True)

    # è®¡ç®—ä¸‹å‘¨æœŸæ¯å¤©æ¶¨å¹…
    # period_df['ä¸‹å‘¨æœŸæ¯å¤©æ¶¨è·Œå¹…'] = period_df['æ¯å¤©æ¶¨è·Œå¹…'].shift(-1)

    # åªä¿ç•™äº¤æ˜“æ—¥çš„æ•°æ®
    period_df = period_df[period_df['æ˜¯å¦äº¤æ˜“'] == 1]

    return period_df


def cal_zdt_price(df):
    """
    è®¡ç®—è‚¡ç¥¨å½“å¤©çš„æ¶¨è·Œåœä»·æ ¼ã€‚åœ¨è®¡ç®—æ¶¨è·Œåœä»·æ ¼çš„æ—¶å€™ï¼ŒæŒ‰ç…§ä¸¥æ ¼çš„å››èˆäº”å…¥ã€‚
    åŒ…å«STè‚¡ï¼Œä½†æ˜¯ä¸åŒ…å«æ–°è‚¡ã€‚

    æ¶¨è·Œåœåˆ¶åº¦è§„åˆ™:
        ---2020å¹´8æœˆ23æ—¥
        éSTè‚¡ç¥¨ 10%
        STè‚¡ç¥¨ 5%

        ---2020å¹´8æœˆ24æ—¥è‡³ä»Š
        æ™®é€šéSTè‚¡ç¥¨ 10%
        æ™®é€šSTè‚¡ç¥¨ 5%

        ç§‘åˆ›æ¿ï¼ˆsh68ï¼‰ 20%ï¼ˆä¸€ç›´æ˜¯20%ï¼Œä¸å—æ—¶é—´é™åˆ¶ï¼‰
        åˆ›ä¸šæ¿ï¼ˆsz3ï¼‰ 20%
        ç§‘åˆ›æ¿å’Œåˆ›ä¸šæ¿å³ä½¿STï¼Œæ¶¨è·Œå¹…é™åˆ¶ä¹Ÿæ˜¯20%

        åŒ—äº¤æ‰€ï¼ˆbjï¼‰ 30%

    å‚æ•°:
    df (DataFrame): å¿…é¡»å¾—æ˜¯æ—¥çº¿æ•°æ®ã€‚å¿…é¡»åŒ…å«çš„å­—æ®µï¼šå‰æ”¶ç›˜ä»·ï¼Œå¼€ç›˜ä»·ï¼Œæœ€é«˜ä»·ï¼Œæœ€ä½ä»·

    è¿”å›:
    DataFrame: åŒ…å«æ¶¨åœä»·ã€è·Œåœä»·ã€ä¸€å­—æ¶¨åœã€ä¸€å­—è·Œåœã€å¼€ç›˜æ¶¨åœã€å¼€ç›˜è·Œåœç­‰å­—æ®µçš„DataFrame
    """
    from decimal import Decimal, ROUND_HALF_UP, ROUND_DOWN
    # è®¡ç®—æ™®é€šè‚¡ç¥¨çš„æ¶¨åœä»·å’Œè·Œåœä»·
    cond = df['è‚¡ç¥¨åç§°'].str.contains('ST')
    df['æ¶¨åœä»·'] = df['å‰æ”¶ç›˜ä»·'] * 1.1
    df['è·Œåœä»·'] = df['å‰æ”¶ç›˜ä»·'] * 0.9
    df.loc[cond, 'æ¶¨åœä»·'] = df['å‰æ”¶ç›˜ä»·'] * 1.05
    df.loc[cond, 'è·Œåœä»·'] = df['å‰æ”¶ç›˜ä»·'] * 0.95

    # è®¡ç®—ç§‘åˆ›æ¿å’Œæ–°è§„åçš„åˆ›ä¸šæ¿çš„æ¶¨åœä»·å’Œè·Œåœä»·
    rule_kcb = df['è‚¡ç¥¨ä»£ç '].str.contains('sh68')  # ç§‘åˆ›æ¿
    new_rule_cyb = (df['äº¤æ˜“æ—¥æœŸ'] > pd.to_datetime('2020-08-23')) & df['è‚¡ç¥¨ä»£ç '].str.contains('sz3')  # æ–°è§„åçš„åˆ›ä¸šæ¿
    df.loc[rule_kcb | new_rule_cyb, 'æ¶¨åœä»·'] = df['å‰æ”¶ç›˜ä»·'] * 1.2
    df.loc[rule_kcb | new_rule_cyb, 'è·Œåœä»·'] = df['å‰æ”¶ç›˜ä»·'] * 0.8

    # è®¡ç®—åŒ—äº¤æ‰€çš„æ¶¨åœä»·å’Œè·Œåœä»·
    cond_bj = df['è‚¡ç¥¨ä»£ç '].str.contains('bj')
    df.loc[cond_bj, 'æ¶¨åœä»·'] = df['å‰æ”¶ç›˜ä»·'] * 1.3
    df.loc[cond_bj, 'è·Œåœä»·'] = df['å‰æ”¶ç›˜ä»·'] * 0.7

    # å››èˆäº”å…¥
    def price_round(x):
        return float(Decimal(x + 1e-7).quantize(Decimal('1.00'), ROUND_HALF_UP))
    df.loc[~cond_bj, 'æ¶¨åœä»·'] = df['æ¶¨åœä»·'].apply(price_round)
    df.loc[~cond_bj, 'è·Œåœä»·'] = df['è·Œåœä»·'].apply(price_round)

    # åŒ—äº¤æ‰€ç‰¹æ®Šå¤„ç†ï¼šåŒ—äº¤æ‰€çš„è§„åˆ™æ˜¯æ¶¨è·Œåœä»·æ ¼å°äºç­‰äº30%ï¼Œä¸åšå››èˆäº”å…¥ï¼Œæ‰€ä»¥è¶…è¿‡30%çš„éƒ¨åˆ†éœ€è¦å‡å»1åˆ†é’±
    def price_round_bj(x):
        return float(Decimal(x).quantize(Decimal('0.00'), rounding=ROUND_DOWN))
    df.loc[cond_bj, 'æ¶¨åœä»·'] = df['æ¶¨åœä»·'].apply(price_round_bj)
    df.loc[cond_bj, 'è·Œåœä»·'] = df['è·Œåœä»·'].apply(price_round_bj)

    # åˆ¤æ–­æ˜¯å¦ä¸€å­—æ¶¨åœ
    df['ä¸€å­—æ¶¨åœ'] = False
    df.loc[df['æœ€ä½ä»·'] >= df['æ¶¨åœä»·'], 'ä¸€å­—æ¶¨åœ'] = True

    # åˆ¤æ–­æ˜¯å¦ä¸€å­—è·Œåœ
    df['ä¸€å­—è·Œåœ'] = False
    df.loc[df['æœ€é«˜ä»·'] <= df['è·Œåœä»·'], 'ä¸€å­—è·Œåœ'] = True

    # åˆ¤æ–­æ˜¯å¦å¼€ç›˜æ¶¨åœ
    df['å¼€ç›˜æ¶¨åœ'] = False
    df.loc[df['å¼€ç›˜ä»·'] >= df['æ¶¨åœä»·'], 'å¼€ç›˜æ¶¨åœ'] = True

    # åˆ¤æ–­æ˜¯å¦å¼€ç›˜è·Œåœ
    df['å¼€ç›˜è·Œåœ'] = False
    df.loc[df['å¼€ç›˜ä»·'] <= df['è·Œåœä»·'], 'å¼€ç›˜è·Œåœ'] = True

    return df


def get_trade_date(index_data: pd.DataFrame) -> pd.DataFrame:
    # ==è·å–äº¤æ˜“æ—¥å†
    url = "https://datacenter-web.eastmoney.com/api/data/v1/get"
    params = {
        "reportName": "RPTA_WEB_ZGXSRL",
        "columns": "ALL",
        "pageSize": 200,
        "sortColumns": "SDATE",
        "sortTypes": -1,
        "callback": f"jQuery1123{random.randint(10000000000000000, 99999999999999999)}_" + str(int(time.time() * 1000)),
        # åŠ¨æ€ç”Ÿæˆæ—¶é—´æˆ³
        "_": int(time.time() * 1000)  # åŠ¨æ€ç”Ÿæˆæ—¶é—´æˆ³
    }

    response = requests.get(url, params=params)
    content = response.text

    # å»é™¤JSONPå°è£…
    start = content.find('(') + 1
    end = content.rfind(')')
    json_data = json.loads(content[start:end])

    # ==å¤„ç†äº¤æ˜“æ—¥å†
    holiday_df = pd.DataFrame(json_data['result']['data'])
    holiday_df = holiday_df[holiday_df['MKT'] == 'Aè‚¡'].sort_values('SDATE').reset_index(drop=True)
    holiday_df['SDATE'] = pd.to_datetime(holiday_df['SDATE'])
    holiday_df['EDATE'] = pd.to_datetime(holiday_df['EDATE'])
    # æ—¥å†ä»æœ€å°çš„æ—¶é—´ç‚¹å¼€å§‹
    start = holiday_df['SDATE'].min()
    # æˆªæ­¢åˆ°æœ€å¤§çš„æ—¶é—´ç‚¹çš„å¹´åº•
    end = pd.to_datetime(f"{holiday_df['EDATE'].max().year}-12-31")

    # åˆ›å»ºæ—¥å†ï¼Œå¹¶æ ‡è®°ä¸äº¤æ˜“çš„æ—¥æœŸ
    date_range = pd.DataFrame(pd.date_range(start=start, end=end), columns=['äº¤æ˜“æ—¥æœŸ'])
    for i in holiday_df.index:
        con = (date_range['äº¤æ˜“æ—¥æœŸ'] >= holiday_df.loc[i, 'SDATE']) & (
                date_range['äº¤æ˜“æ—¥æœŸ'] <= holiday_df.loc[i, 'EDATE'])
        date_range.loc[con, 'äº¤æ˜“æ—¥æœŸ'] = np.nan

    # æ­£å¸¸çš„å‘¨æœ«ä¹Ÿæ˜¯ä¸äº¤æ˜“çš„
    con = date_range['äº¤æ˜“æ—¥æœŸ'].dt.weekday.isin([5, 6])
    date_range.loc[con, 'äº¤æ˜“æ—¥æœŸ'] = np.nan
    date_range = date_range[date_range['äº¤æ˜“æ—¥æœŸ'].notnull()]

    # ==åˆå¹¶äº¤æ˜“æ—¥
    trade_date_df = pd.concat([index_data[['äº¤æ˜“æ—¥æœŸ']], date_range], ignore_index=True)
    trade_date_df = trade_date_df.drop_duplicates(subset='äº¤æ˜“æ—¥æœŸ', keep='first').reset_index(drop=True)
    return trade_date_df


def save_latest_result(conf, select_result_df):
    # å¯¼å…¥æŒ‡æ•°
    index_data = conf.read_index_with_trading_date()
    last_date = select_result_df['äº¤æ˜“æ—¥æœŸ'].max()
    period_end = index_data[index_data['äº¤æ˜“æ—¥æœŸ'] == last_date][f'{conf.strategy.hold_period_name}ç»ˆæ­¢æ—¥'].iloc[0]

    if pd.isnull(conf.end_date) and period_end:
        # è·å¾—æœ€æ–°çš„é€‰è‚¡ç»“æœ
        new_select_df = select_result_df[select_result_df['äº¤æ˜“æ—¥æœŸ'] == last_date].rename(
            columns={'äº¤æ˜“æ—¥æœŸ': 'é€‰è‚¡æ—¥æœŸ'})
        # æ¬¡äº¤æ˜“æ—¥æ‰æ˜¯çœŸæ­£çš„äº¤æ˜“æ—¥æœŸ
        trade_date = index_data[index_data['äº¤æ˜“æ—¥æœŸ'] == last_date]['æ¬¡äº¤æ˜“æ—¥'].iloc[0]
        new_select_df['äº¤æ˜“æ—¥æœŸ'] = trade_date
        # åªä¿ç•™éœ€è¦çš„åˆ—
        keep_cols = ['é€‰è‚¡æ—¥æœŸ', 'äº¤æ˜“æ—¥æœŸ', 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°']
        new_select_df = new_select_df[keep_cols]

        new_result_path = conf.get_result_folder() / 'æœ€æ–°é€‰è‚¡ç»“æœ.csv'
        if new_result_path.exists():
            old_result_df = pd.read_csv(new_result_path, encoding='utf-8-sig', parse_dates=['é€‰è‚¡æ—¥æœŸ', 'äº¤æ˜“æ—¥æœŸ'])
            # åˆ é™¤é‡å¤çš„é€‰è‚¡ç»“æœ
            con1 = old_result_df['é€‰è‚¡æ—¥æœŸ'] != last_date
            con2 = old_result_df['äº¤æ˜“æ—¥æœŸ'] != trade_date
            old_result_df = old_result_df[con1 & con2]
            result_df = pd.concat([old_result_df, new_select_df], ignore_index=True)
        else:
            result_df = new_select_df

        result_df.to_csv(new_result_path, encoding='utf-8-sig', index=False)


def select_analysis(conf, select_df: pd.DataFrame, top_n=10, show_plot=True) -> None:
    # æ–°å¢å‡½æ•°ï¼šåˆ†ææ¯å¹´çš„é€‰è‚¡æƒ…å†µ

    # æ–°å¢ï¼šè·å–æ‰€æœ‰è‚¡ç¥¨æœ€æ–°çš„åå­—
    last_stock_name = pd.DataFrame(select_df.groupby('è‚¡ç¥¨ä»£ç ')['è‚¡ç¥¨åç§°'].last()).reset_index()
    # æ¯å¹´é€‰è‚¡æ¬¡æ•°nçš„è‚¡ç¥¨
    select_df['å¹´ä»½'] = select_df['äº¤æ˜“æ—¥æœŸ'].dt.year
    # æ¯å¹´çš„æ¬¡æ•°
    year_count = pd.DataFrame(select_df.groupby(['å¹´ä»½', 'è‚¡ç¥¨ä»£ç '])['è‚¡ç¥¨ä»£ç '].count()).rename(
        columns={'è‚¡ç¥¨ä»£ç ': 'é€‰ä¸­æ¬¡æ•°'}).reset_index()
    # åˆå¹¶è‚¡ç¥¨åç§°
    year_count = year_count.merge(last_stock_name, on='è‚¡ç¥¨ä»£ç ', how='left')
    # è®¡ç®—é€‰ä¸­æ¬¡æ•°æ’å
    year_count['é€‰ä¸­æ¬¡æ•°_æ’å'] = year_count.groupby('å¹´ä»½')['é€‰ä¸­æ¬¡æ•°'].rank(method='min', ascending=False)
    year_count = year_count[year_count['é€‰ä¸­æ¬¡æ•°_æ’å'] <= top_n]
    # æ¯å¹´é€‰æ‹©æ’åé å‰çš„è‚¡ç¥¨
    groups = year_count.groupby('å¹´ä»½')
    years = pd.DataFrame()
    for t, g in groups:
        inx = 0 if pd.isnull(years.index.max()) else years.index.max() + 1
        years.loc[inx, 'å¹´ä»½'] = str(int(t))
        g = g.sort_values(by='é€‰ä¸­æ¬¡æ•°_æ’å').reset_index()
        g['å†å¹´é€‰è‚¡æœ€å¤š'] = g['è‚¡ç¥¨åç§°'].astype(str) + '_' + g['é€‰ä¸­æ¬¡æ•°'].astype(str) + ' '
        txt = g['å†å¹´é€‰è‚¡æœ€å¤š'].sum()
        years.loc[inx, 'å†å¹´é€‰è‚¡æœ€å¤š'] = txt
    print(years)
    years.to_csv(conf.get_result_folder() / f'{conf.strategy.name}å†å¹´é€‰è‚¡æœ€å¤š.csv', encoding='utf-8-sig')

    # è®¡ç®—æ¯å¤©çš„å¹³å‡å¸‚å€¼ & å¹³å‡åˆ†ä½æ•°
    period_market_value = select_df.groupby('äº¤æ˜“æ—¥æœŸ').agg({'æ€»å¸‚å€¼': 'mean', 'å¸‚å€¼åˆ†ä½': 'mean'}).reset_index()
    period_market_value['æ€»å¸‚å€¼'] /= 100000000
    # ç”»å›¾
    data_dict = {'å¹³å‡å¸‚å€¼': 'æ€»å¸‚å€¼'}
    ds = period_market_value['æ€»å¸‚å€¼']
    txt = f'å‡å€¼ï¼š{ds.mean():.2f}ï¼ˆäº¿ï¼‰  ä¸­å€¼ï¼š{ds.median():.2f}ï¼ˆäº¿ï¼‰  æœ€å°å€¼ï¼š{ds.min():.2f}ï¼ˆäº¿ï¼‰  æœ€å¤§å€¼ï¼š{ds.max():.2f}ï¼ˆäº¿ï¼‰'
    draw_equity_curve_plotly(period_market_value, data_dict, 'äº¤æ˜“æ—¥æœŸ', desc=txt, title='æŒä»“å¹³å‡å¸‚å€¼',
              path=conf.get_result_folder() / 'å¹³å‡å¸‚å€¼.html', show=show_plot)

    data_dict = {'å¹³å‡å¸‚å€¼åˆ†ä½æ•°': 'å¸‚å€¼åˆ†ä½'}
    ds = period_market_value['å¸‚å€¼åˆ†ä½']
    txt = f'å‡å€¼ï¼š{ds.mean():.2f}  ä¸­å€¼ï¼š{ds.median():.2f}  æœ€å°å€¼ï¼š{ds.min():.2f}  æœ€å¤§å€¼ï¼š{ds.max():.2f}'
    draw_equity_curve_plotly(period_market_value, data_dict, 'äº¤æ˜“æ—¥æœŸ', desc=txt, title='æŒä»“å¹³å‡å¸‚å€¼åˆ†ä½æ•°',
              path=conf.get_result_folder() / 'å¹³å‡å¸‚å€¼åˆ†ä½æ•°.html', show=show_plot)
